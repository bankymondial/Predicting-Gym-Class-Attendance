{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50a6c054-26b3-4881-91e7-f089dec06eae",
   "metadata": {},
   "source": [
    "## Training ExtraTreesClassifier and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4045b4a7-d415-4a5e-b9c3-b5a4cd5da289",
   "metadata": {},
   "source": [
    "### 1. Data Preparation and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0949901-01d4-4c58-afa7-701d150a7313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a2d987-3428-413c-86c0-001ca57624a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"fitness_class_2212.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab9260-607e-4ba7-972b-065d4d5ba335",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.weight = df.weight.fillna(df.weight.median()) #For ExtraTreesClassifier, there is a need to handle missing values, not for XGBoost\n",
    "df.drop('booking_id', axis=1, inplace=True)  # drop the booking_id column as it's irrelevant to the analysis\n",
    "df.days_before = df.days_before.str.replace(r' days$', '', regex=True) # Remove ' days'\n",
    "df.days_before = pd.to_numeric(df.days_before, errors='coerce').astype(int) # Convert the cleaned values to integers\n",
    "\n",
    "df.day_of_week = df.day_of_week.replace({'Wednesday': 'Wed', 'Monday': 'Mon'})  # Replace 'Wednesday' with 'Wed'\n",
    "df.day_of_week = df.day_of_week.str.replace(r'Fri\\.$', 'Fri', regex=True)  # Use raw string to remove period from 'Fri.'\n",
    "df.category = df.category.replace('-', 'Unknown')  # Replace with \"Unknown\" instead of NaN to prevent information loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d3e88-aae4-436a-9ea1-7dd5b6fe42f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "059f9959-4639-4399-8288-5e2a4b9a4cc6",
   "metadata": {},
   "source": [
    "### 2. Splitting the data, extracting target variables, dropping target column and transforming features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d2d906-5808-4826-9c3a-d52bf327d934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train['attended'].values\n",
    "y_val = df_val['attended'].values\n",
    "y_test = df_test['attended'].values\n",
    "\n",
    "del df_train['attended']\n",
    "del df_val['attended']\n",
    "del df_test['attended']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00332663-06ef-408d-81aa-16298f9b4f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c45a591-94e6-4eb4-811d-5daa4bfe20f1",
   "metadata": {},
   "source": [
    "### 3a. Training ExtraTreesClassifier\n",
    "- This class implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. https://scikit-learn.org/dev/modules/generated/sklearn.ensemble.ExtraTreesClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f733ada-6003-4351-a002-2a8488c4ac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "val_dicts = df_val.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dicts)\n",
    "\n",
    "test_dicts = df_test.to_dict(orient='records')\n",
    "X_test = dv.transform(test_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f71e84e-5a24-4780-8475-9ea665e1ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(n_estimators=100, random_state=1)\n",
    "et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3eb7e39-35c5-412e-9c4e-f39bb7088aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = et.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, y_pred)\n",
    "print(\"Validation AUC:\", val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c176f90a-21bd-4d0a-a101-1ff9bb26c715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfe75e01-dd9c-496c-bd53-c16c74740ede",
   "metadata": {},
   "source": [
    "#### 3b. Tuning the parameters with GridSearchCV (to search for the best combination of parameters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0af9b2-f7de-434d-8349-8605f37fb476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04a29c7-40bf-4caa-9410-65e526896096",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"n_estimators\": [50, 100, 150, 200],\n",
    "    \"max_depth\": [10, 20, 30, None],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e87f5e-b4a3-42c9-812a-29856d54ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "et = ExtraTreesClassifier(random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abc62f1-4d91-4485-b48c-5ba44a1e1222",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3038eec-f3c3-44e4-bee2-bb9785d8de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(\n",
    "    estimator=et,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    verbose=0,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59da2720-65ad-486d-9529-331699e1eec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tqdm(total=len(param_grid)) as pbar:\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f58c95-d9d7-473f-8de8-91f36495d99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(\"Best Validation AUC:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae7122-5ae0-4ab2-a9cf-49e90ff19c3c",
   "metadata": {},
   "source": [
    "##### Explanation of result:\n",
    "- `max_depth=10`: This limits the depth of each tree to 10 levels, balancing model complexity and overfitting. A smaller depth prevents the model from memorizing the training data.\n",
    "- `max_features=None`: The model considers all features when determining splits, potentially increasing performance because there are only 6 features.\n",
    "- `min_samples_leaf=2`: Each leaf node must have at least 2 samples, preventing splits that would result in very small or pure leaf nodes. This can help reduce overfitting.\n",
    "- `min_samples_split=10`: A node must have at least 10 samples to be considered for splitting, further controlling overfitting.\n",
    "- `n_estimators=50`: The model uses 50 trees in the ensemble, which is reasonable for your dataset size (1500 rows). More trees would increase training time but may not significantly improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24439ad6-a268-4408-b315-af2d4d6f6d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f229fea-31e2-473b-9daf-5a813596a384",
   "metadata": {},
   "source": [
    "#### 3c. Training the model with the Best Parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c371b6a-2ae4-421d-95c7-14e64d9e9f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_et = ExtraTreesClassifier(\n",
    "    max_depth=10,\n",
    "    max_features=None,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=10,\n",
    "    n_estimators=50,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "best_et.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f67d76-1737-4a59-b403-da2e55b16606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating on validation dataset\n",
    "\n",
    "y_pred = best_et.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, y_pred)\n",
    "print(\"Validation AUC:\", val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff79ada-a7d5-42a6-a803-d92432d8f907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "\n",
    "y_pred = best_et.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081a66c-9aeb-4fe6-b2be-5e0401955836",
   "metadata": {},
   "source": [
    "#### The model appears to be slightly overfitting to the training and validation data given that the `Test AUC: 0.745` is lower than the `Validation AUC: 0.818`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401e6187-c7ce-4c61-bfd6-de35078fe276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d095d6c7-1227-4946-a931-b86edc8fa233",
   "metadata": {},
   "source": [
    "#### 3d. Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1c0d0-cef5-419b-8b6e-90156c8546cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_scores = cross_val_score(\n",
    "    best_et,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\"\n",
    ")\n",
    "\n",
    "print(\"Cross-Validation AUC:\", np.mean(cv_scores), \"+-\", np.std(cv_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0c6fe7-2f0d-404a-bbdd-dfb5bd935ecc",
   "metadata": {},
   "source": [
    "#### `The Cross-Validation AUC: 0.815` does indicate the the model is performing consistently across folds. Moving on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920a1f3-41fa-4f39-a535-7d1bd1f2a756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fd26d31-2c71-41b1-a6bb-7c38befa3ad3",
   "metadata": {},
   "source": [
    "### 4a. Training, tuning and evaluating an XGBoost model\n",
    "- XG Boost: XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable. It implements machine learning algorithms under the Gradient Boosting framework. https://www.nvidia.com/en-us/glossary/xgboost/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55cf260-bf14-4cac-b410-4ee590206763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd876581-faa0-4b36-b649-915016ec717d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14694cd7-4572-413f-9b95-0afc0bcdf2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457eebc0-3694-47a9-a08b-e38a1be3e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"max_depth\": 10,\n",
    "    \"eta\": 0.1,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b050f01-01fd-462b-868a-299d6e2565c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85638798-141e-4547-94b3-f66a244819fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "watchlist = [(dtrain, \"train\"), (dval, \"val\")]\n",
    "\n",
    "model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=100,\n",
    "    evals=watchlist,\n",
    "    early_stopping_rounds=10,\n",
    "    verbose_eval=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd75b1e-dc4f-4436-b2d4-57088b62a0bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba7656-2a0e-458e-9165-019134f0343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(dtest)\n",
    "\n",
    "test_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"XGBoost Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1658e2f0-2060-4ce6-9198-feca09090628",
   "metadata": {},
   "source": [
    "#### An XGBoost Test AUC of 0.747 is slightly better than that of the ExtraTreesClassifier Test AUC of 0.745 but it's still not a significant improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0b5d4-89ce-43c6-88bc-74473cf900ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e32db4d9-5651-48b5-822d-db2f39ddeae6",
   "metadata": {},
   "source": [
    "#### The imbalance in the dataset appears to be affecting the performance of XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee92560-11e2-4755-8112-c51c5cda67f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac559269-ab91-41e5-9bf7-cb63e953c69a",
   "metadata": {},
   "source": [
    "#### 4b. Ensemble Models: Combine predictions from multiple models, such as XGBoost, ExtraTrees, and LightGBM, using a soft voting approach. This often improves generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf359c-23ff-4c9c-b78f-ba9234ba86de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('et', best_et),\n",
    "    ],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"Ensemble Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ead54-1d40-4896-9ad7-abac7cf216e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6c7a02-a4f9-40e3-80cd-d6ca54b956c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tuning the Ensemble model\n",
    "\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', best_xgb),\n",
    "        ('et', best_et),\n",
    "    ],\n",
    "    voting='soft',\n",
    "    weights=[2, 1]  # Give more weight to XGBoost if it performs better\n",
    ")\n",
    "\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_test_pred = ensemble_model.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, y_test_pred)\n",
    "print(\"Weighted Ensemble Test AUC:\", test_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481b7038-8cfb-440e-a433-04d070135ff3",
   "metadata": {},
   "source": [
    "#### The ensemble has successfully captured complementary strengths from both XGBoost and ExtraTreesClassifier.\n",
    "- The weighted voting scheme gave XGBoost, the stronger individual performer, more influence on the final predictions.\n",
    "- This AUC improvement suggests that the ensemble is robust and better at distinguishing between classes on unseen data compared to individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1a72a8-7141-4672-beef-920ed2096327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a81b0df6-085e-4096-a743-6ea7c17ad38a",
   "metadata": {},
   "source": [
    "### 5. Selecting the final model\n",
    "- Choosing between logistic regression, ExtraTreesClassifier and XGBoost\n",
    "- Training the final model\n",
    "- Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e635c8e5-2e8c-44cf-afa5-d71479eb1a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b523469-ca56-4f8e-82cc-af64636b68a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac401613-f2b6-42b9-b472-8c60b5f009b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2cb22-9c66-43d2-8f87-8610251ad49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19d833-92e6-4353-b9d2-496cf2e23f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a179d8b9-d51b-4625-a907-6fd258c618c6",
   "metadata": {},
   "source": [
    "##### Feature Importance for further insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26eff1-04ab-4dac-9fc8-6832906f3b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average feature importances from both models\n",
    "feature_importances = (\n",
    "    np.array(best_xgb.feature_importances_) + np.array(best_et.feature_importances_)\n",
    ") / 2\n",
    "\n",
    "# Feature names\n",
    "feature_names = dv.feature_names_\n",
    "\n",
    "# Plot\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_importances)), feature_importances[indices], align=\"center\")\n",
    "plt.xticks(range(len(feature_importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.title(\"Ensemble Feature Importance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4194caf-038b-4158-be72-e08c60ff1d40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
